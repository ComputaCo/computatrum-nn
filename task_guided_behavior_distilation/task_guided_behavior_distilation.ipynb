{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mouse\n",
    "import keyboard\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import gym\n",
    "import transformers\n",
    "\n",
    "import ComputerEnv\n",
    "\n",
    "from .task_guided_behavior_distilation_env_wrapper \\\n",
    "  import TaskGuidedBehaviorDistilationEnvWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_demonstrations_to_collect = 10\n",
    "demonstration_length = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "task_encoder = transformers.TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def encode(sentence: str):\n",
    "  tokens = task_tokenizer.encode(sentence, return_tensors='tf')\n",
    "  return task_encoder(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_demo():\n",
    "  replayer.start_record()\n",
    "  sleep(demonstration_length)\n",
    "  replayer.stop_record()\n",
    "  task_description = input(\"Enter task description: \")\n",
    "  yield {\n",
    "    'demo': demo, \n",
    "    'task_description': task_description,\n",
    "    'task_description_encoding': encode(task_description),\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_demos = [collect_demo() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayPolicy:\n",
    "\n",
    "  def __init__(self, demo, task_description):\n",
    "    self.demo = demo\n",
    "    self.task_description = task_description\n",
    "    self.demo_index = 0\n",
    "\n",
    "  def __call__(self, obs):\n",
    "    del obs\n",
    "\n",
    "    def replay_policy(self, obs):\n",
    "      replay(self.demo[self.demo_index])\n",
    "      if obs['task'] == self.demo:\n",
    "        return {'task_eval': 1.0, 'task_eval_confidence': 1.0}\n",
    "      else:\n",
    "        return {'task_eval': -1.0, 'task_eval_confidence': 1.0}\n",
    "\n",
    "  @property\n",
    "  def done(self):\n",
    "    return self.demo_index == len(self.demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(policy):\n",
    "  records = []\n",
    "  for demo, task_description in labeled_demos:\n",
    "    env = ComputerEnv.LocalGUIEnv(...)\n",
    "    replay_policy = ReplayPolicy(demo, task_description)\n",
    "    env = TaskGuidedBehaviorDistilationEnvWrapper(\n",
    "      env=env,\n",
    "      task=task_description,\n",
    "      teacher_policy=replay_policy,\n",
    "      loss_fn=tf.keras.losses.binary_crossentropy,\n",
    "      task_space=gym.spaces.Box(None, None, shape=[768,]),\n",
    "      task_eval_space=gym.spaces.Box(0, 1, shape=[1]),\n",
    "    )\n",
    "    step = 0\n",
    "    obs, done = env.reset(), False\n",
    "    while not (done or replay_policy.done):\n",
    "      action = policy(obs)\n",
    "      obs, reward, done, info = env.step(action)\n",
    "      record = {\n",
    "        'step': step,\n",
    "        'task': obs['task'],\n",
    "        'task_eval': action['task_eval'],\n",
    "        'task_eval_confidence': action['task_eval_confidence'],\n",
    "        'reward': reward,\n",
    "      }\n",
    "      record.update({\n",
    "        f'info_{key}': value\n",
    "        for key, value in info.items()\n",
    "      })\n",
    "      records.append(record)\n",
    "      step += 1\n",
    "  return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPolicy:\n",
    "\n",
    "  def __call__(self, obs):\n",
    "    return {'task_eval': np.random.uniform(0, 1), 'task_eval_confidence': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = RandomPolicy()\n",
    "records = evaluate(policy)\n",
    "df = pd.DataFrame(records)\n",
    "display(df)\n",
    "sns.barplot(data=df, x='task', y='reward')\n",
    "plt.show()\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1)\n",
    "sns.lineplot(data=df, x='step', y='task_eval', hue='task', ax=axes[0])\n",
    "sns.lineplot(data=df, x='step', y='task_eval_confidence', hue='task', ax=axes[1])\n",
    "sns.lineplot(data=df, x='step', y='reward', hue='task', ax=axes[2])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "605fe966a75bc2c3dfa708e269323e6491854b30a36f4e77953579e94649bfba"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
